# ==============================================================
# ğŸ’¬ app/routes/chat_routes.py
# --------------------------------------------------------------
# Rota para interaÃ§Ã£o generativa com o assistente de sustentaÃ§Ã£o.
# ==============================================================

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from app.utils.validation import is_prompt_valid  # ou validar_pergunta, conforme versÃ£o final
from app.services.openai_client import gerar_resposta

router = APIRouter(prefix="/chat", tags=["Chat Assistente"])

# ==============================================================
# ğŸ“¥ Modelo de entrada
# ==============================================================
class ChatRequest(BaseModel):
    pergunta: str

# ==============================================================
# ğŸ“¤ Modelo de saÃ­da (opcional, melhora documentaÃ§Ã£o Swagger)
# ==============================================================
class ChatResponse(BaseModel):
    pergunta: str
    resposta: str

# ==============================================================
# ğŸ§  Endpoint principal
# ==============================================================
@router.post("/", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """
    Recebe uma pergunta e retorna uma resposta contextual do assistente tÃ©cnico.
    O assistente responde apenas perguntas relacionadas a logs, falhas,
    infraestrutura, integraÃ§Ãµes e sistemas corporativos.
    """
    pergunta = request.pergunta.strip()

    # ğŸ” ValidaÃ§Ã£o de contexto
    if not is_prompt_valid(pergunta):
        print(f"ğŸš« Pergunta bloqueada por contexto: {pergunta}")
        raise HTTPException(
            status_code=400,
            detail=(
                "âŒ Pergunta fora do contexto tÃ©cnico. "
                "O assistente responde apenas sobre sistemas, logs e sustentaÃ§Ã£o."
            ),
        )

    print(f"ğŸ’¬ Pergunta recebida: {pergunta}")

    # ğŸ§  GeraÃ§Ã£o de resposta via OpenAI
    resposta = gerar_resposta(pergunta)
    print(f"âœ… Resposta gerada ({len(resposta)} caracteres).")

    return {"pergunta": pergunta, "resposta": resposta}
